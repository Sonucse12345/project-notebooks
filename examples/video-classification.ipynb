{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f938cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\r\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pytorchvideo remotezip transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0058e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import remotezip as rz\n",
    "\n",
    "\n",
    "def list_files_from_zip_url(zip_url):\n",
    "    \"\"\"List the files in each class of the dataset given a URL with the zip file.\n",
    "\n",
    "    Args:\n",
    "      zip_url: A URL from which the files can be extracted from.\n",
    "\n",
    "    Returns:\n",
    "      List of files in each of the classes.\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    with rz.RemoteZip(zip_url) as zip:\n",
    "        for zip_info in zip.infolist():\n",
    "            files.append(zip_info.filename)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "076d3cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UCF101/v_ApplyEyeMakeup_g01_c01.avi',\n",
       " 'UCF101/v_ApplyEyeMakeup_g01_c02.avi',\n",
       " 'UCF101/v_ApplyEyeMakeup_g01_c03.avi',\n",
       " 'UCF101/v_ApplyEyeMakeup_g01_c04.avi',\n",
       " 'UCF101/v_ApplyEyeMakeup_g01_c05.avi',\n",
       " 'UCF101/v_ApplyEyeMakeup_g01_c06.avi',\n",
       " 'UCF101/v_ApplyEyeMakeup_g02_c01.avi',\n",
       " 'UCF101/v_ApplyEyeMakeup_g02_c02.avi',\n",
       " 'UCF101/v_ApplyEyeMakeup_g02_c03.avi',\n",
       " 'UCF101/v_ApplyEyeMakeup_g02_c04.avi']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://storage.googleapis.com/thumos14_files/UCF101_videos.zip\"\n",
    "files = list_files_from_zip_url(url)\n",
    "files = [f for f in files if f.endswith(\".avi\")]\n",
    "files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37d41dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(fname):\n",
    "    \"\"\"Retrieve the name of the class given a filename.\n",
    "\n",
    "    Args:\n",
    "      fname: Name of the file in the UCF101 dataset.\n",
    "\n",
    "    Returns:\n",
    "      Class that the file belongs to.\n",
    "    \"\"\"\n",
    "    return fname.split(\"_\")[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f22c0619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "\n",
    "def get_files_per_class(files):\n",
    "    \"\"\"Retrieve the files that belong to each class.\n",
    "\n",
    "    Args:\n",
    "      files: List of files in the dataset.\n",
    "\n",
    "    Returns:\n",
    "      Dictionary of class names (key) and files (values).\n",
    "    \"\"\"\n",
    "    files_for_class = collections.defaultdict(list)\n",
    "    for fname in files:\n",
    "        class_name = get_class(fname)\n",
    "        files_for_class[class_name].append(fname)\n",
    "    return files_for_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30f2354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_for_class = get_files_per_class(files)\n",
    "classes = list(files_for_class.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "585a6ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes: 101\n",
      "Num videos for class[0]: 145\n"
     ]
    }
   ],
   "source": [
    "print(\"Num classes:\", len(classes))\n",
    "print(\"Num videos for class[0]:\", len(files_for_class[classes[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5de896fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_subset_of_classes(files_for_class, classes, files_per_class):\n",
    "    \"\"\"Create a dictionary with the class name and a subset of the files in that class.\n",
    "\n",
    "    Args:\n",
    "      files_for_class: Dictionary of class names (key) and files (values).\n",
    "      classes: List of classes.\n",
    "      files_per_class: Number of files per class of interest.\n",
    "\n",
    "    Returns:\n",
    "      Dictionary with class as key and list of specified number of video files in that class.\n",
    "    \"\"\"\n",
    "    files_subset = dict()\n",
    "\n",
    "    for class_name in classes:\n",
    "        class_files = files_for_class[class_name]\n",
    "        files_subset[class_name] = class_files[:files_per_class]\n",
    "\n",
    "    return files_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b79ec1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ApplyEyeMakeup',\n",
       " ['UCF101/v_ApplyEyeMakeup_g01_c01.avi',\n",
       "  'UCF101/v_ApplyEyeMakeup_g01_c02.avi',\n",
       "  'UCF101/v_ApplyEyeMakeup_g01_c03.avi',\n",
       "  'UCF101/v_ApplyEyeMakeup_g01_c04.avi',\n",
       "  'UCF101/v_ApplyEyeMakeup_g01_c05.avi',\n",
       "  'UCF101/v_ApplyEyeMakeup_g01_c06.avi',\n",
       "  'UCF101/v_ApplyEyeMakeup_g02_c01.avi',\n",
       "  'UCF101/v_ApplyEyeMakeup_g02_c02.avi',\n",
       "  'UCF101/v_ApplyEyeMakeup_g02_c03.avi',\n",
       "  'UCF101/v_ApplyEyeMakeup_g02_c04.avi'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[0], files_for_class[classes[0]][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3e1520f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ApplyEyeMakeup',\n",
       " 'ApplyLipstick',\n",
       " 'Archery',\n",
       " 'BabyCrawling',\n",
       " 'BalanceBeam',\n",
       " 'BandMarching',\n",
       " 'BaseballPitch',\n",
       " 'BasketballDunk',\n",
       " 'Basketball',\n",
       " 'BenchPress']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 10\n",
    "files_per_classes = 50\n",
    "\n",
    "files_subset = select_subset_of_classes(\n",
    "    files_for_class, classes[:num_classes], files_per_classes\n",
    ")\n",
    "list(files_subset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d431cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from urllib import request\n",
    "import pathlib\n",
    "\n",
    "\n",
    "def download_from_zip(zip_url, to_dir, file_names):\n",
    "    \"\"\"Download the contents of the zip file from the zip URL.\n",
    "\n",
    "    Args:\n",
    "      zip_url: A URL with a zip file containing data.\n",
    "      to_dir: A directory to download data to.\n",
    "      file_names: Names of files to download.\n",
    "    \"\"\"\n",
    "    with rz.RemoteZip(zip_url) as zip:\n",
    "        for fn in tqdm.tqdm(file_names):\n",
    "            class_name = get_class(fn)\n",
    "            zip.extract(fn, str(to_dir / class_name))\n",
    "            unzipped_file = to_dir / class_name / fn\n",
    "\n",
    "            fn = pathlib.Path(fn).parts[-1]\n",
    "            output_file = to_dir / class_name / fn\n",
    "            unzipped_file.rename(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fc6a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_class_lists(files_for_class, count):\n",
    "    \"\"\"Returns the list of files belonging to a subset of data as well as the remainder of\n",
    "    files that need to be downloaded.\n",
    "\n",
    "    Args:\n",
    "      files_for_class: Files belonging to a particular class of data.\n",
    "      count: Number of files to download.\n",
    "\n",
    "    Returns:\n",
    "      Files belonging to the subset of data and dictionary of the remainder of files that need to be downloaded.\n",
    "    \"\"\"\n",
    "    split_files = []\n",
    "    remainder = {}\n",
    "    for cls in files_for_class:\n",
    "        split_files.extend(files_for_class[cls][:count])\n",
    "        remainder[cls] = files_for_class[cls][count:]\n",
    "    return split_files, remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72612e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "def download_ufc_101_subset(zip_url, num_classes, splits, download_dir):\n",
    "    \"\"\"Download a subset of the UFC101 dataset and split them into various parts, such as\n",
    "    training, validation, and test.\n",
    "\n",
    "    Args:\n",
    "      zip_url: A URL with a ZIP file with the data.\n",
    "      num_classes: Number of labels.\n",
    "      splits: Dictionary specifying the training, validation, test, etc. (key) division of data\n",
    "              (value is number of files per split).\n",
    "      download_dir: Directory to download data to.\n",
    "\n",
    "    Return:\n",
    "      Mapping of the directories containing the subsections of data.\n",
    "    \"\"\"\n",
    "    files = list_files_from_zip_url(zip_url)\n",
    "    for f in files:\n",
    "        path = os.path.normpath(f)\n",
    "        tokens = path.split(os.sep)\n",
    "        if len(tokens) <= 2:\n",
    "            files.remove(\n",
    "                f\n",
    "            )  # Remove that item from the list if it does not have a filename\n",
    "\n",
    "    files_for_class = get_files_per_class(files)\n",
    "\n",
    "    classes = list(files_for_class.keys())[:num_classes]\n",
    "\n",
    "    for cls in classes:\n",
    "        random.shuffle(files_for_class[cls])\n",
    "\n",
    "    # Only use the number of classes you want in the dictionary\n",
    "    files_for_class = {x: files_for_class[x] for x in classes}\n",
    "\n",
    "    dirs = {}\n",
    "    for split_name, split_count in splits.items():\n",
    "        print(split_name, \":\")\n",
    "        split_dir = download_dir / split_name\n",
    "        split_files, files_for_class = split_class_lists(files_for_class, split_count)\n",
    "        download_from_zip(zip_url, split_dir, split_files)\n",
    "        dirs[split_name] = split_dir\n",
    "\n",
    "    return dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea121d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:38<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:29<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:28<00:00,  3.51it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_root_path = \"./UCF101_subset/\"\n",
    "download_dir = pathlib.Path(dataset_root_path)\n",
    "subset_paths = download_ufc_101_subset(\n",
    "    url,\n",
    "    num_classes=num_classes,\n",
    "    splits={\"train\": 30, \"val\": 10, \"test\": 10},\n",
    "    download_dir=download_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4720ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos: 500\n"
     ]
    }
   ],
   "source": [
    "video_count_train = len(list(download_dir.glob(\"train/*/*.avi\")))\n",
    "video_count_val = len(list(download_dir.glob(\"val/*/*.avi\")))\n",
    "video_count_test = len(list(download_dir.glob(\"test/*/*.avi\")))\n",
    "video_total = video_count_train + video_count_val + video_count_test\n",
    "print(f\"Total videos: {video_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d392c35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('UCF101_subset/train/BabyCrawling/v_BabyCrawling_g25_c05.avi'),\n",
       " PosixPath('UCF101_subset/train/BabyCrawling/v_BabyCrawling_g06_c02.avi'),\n",
       " PosixPath('UCF101_subset/train/BabyCrawling/v_BabyCrawling_g02_c05.avi'),\n",
       " PosixPath('UCF101_subset/train/BabyCrawling/v_BabyCrawling_g12_c05.avi'),\n",
       " PosixPath('UCF101_subset/train/BabyCrawling/v_BabyCrawling_g22_c02.avi')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_video_file_paths = (\n",
    "    list(download_dir.glob(\"train/*/*.avi\"))\n",
    "    + list(download_dir.glob(\"val/*/*.avi\"))\n",
    "    + list(download_dir.glob(\"test/*/*.avi\"))\n",
    ")\n",
    "all_video_file_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e0c4036",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = sorted({str(path).split(\"/\")[2] for path in all_video_file_paths})\n",
    "label2id = {label: i for i, label in enumerate(class_labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "450e8c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !find ./UCF101_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b54e9503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VideoMAEForVideoClassification were not initialized from the model checkpoint at MCG-NJU/videomae-base-finetuned-kinetics and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([400, 768]) in the checkpoint and torch.Size([10, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([400]) in the checkpoint and torch.Size([10]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import VideoMAEFeatureExtractor, VideoMAEForVideoClassification\n",
    "\n",
    "model_ckpt = \"MCG-NJU/videomae-base-finetuned-kinetics\"\n",
    "\n",
    "feature_extractor = VideoMAEFeatureExtractor.from_pretrained(model_ckpt)\n",
    "model = VideoMAEForVideoClassification.from_pretrained(\n",
    "    model_ckpt,\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    ignore_mismatched_sizes=True,  # provide this in case you're planning to fine-tune an already fine-tuned checkpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02d443bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VideoMAEFeatureExtractor {\n",
       "  \"do_center_crop\": true,\n",
       "  \"do_normalize\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"feature_extractor_type\": \"VideoMAEFeatureExtractor\",\n",
       "  \"image_mean\": [\n",
       "    0.485,\n",
       "    0.456,\n",
       "    0.406\n",
       "  ],\n",
       "  \"image_std\": [\n",
       "    0.229,\n",
       "    0.224,\n",
       "    0.225\n",
       "  ],\n",
       "  \"resample\": 2,\n",
       "  \"size\": 224\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbab5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorchvideo.data\n",
    "\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    Normalize,\n",
    "    RandomShortSideScale,\n",
    "    RemoveKey,\n",
    "    ShortSideScale,\n",
    "    UniformTemporalSubsample,\n",
    ")\n",
    "\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    Lambda,\n",
    "    RandomCrop,\n",
    "    RandomHorizontalFlip,\n",
    "    Resize,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c37e925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = feature_extractor.image_mean\n",
    "std = feature_extractor.image_std\n",
    "resize_to = feature_extractor.size\n",
    "clip_duration = 2\n",
    "\n",
    "\n",
    "train_transform = Compose(\n",
    "    [\n",
    "        ApplyTransformToKey(\n",
    "            key=\"video\",\n",
    "            transform=Compose(\n",
    "                [\n",
    "                    UniformTemporalSubsample(8),\n",
    "                    Lambda(lambda x: x / 255.0),\n",
    "                    Normalize(mean, std),\n",
    "                    RandomShortSideScale(min_size=256, max_size=320),\n",
    "                    RandomCrop(resize_to),\n",
    "                    RandomHorizontalFlip(p=0.5),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "train_dataset = pytorchvideo.data.Ucf101(\n",
    "    data_path=os.path.join(dataset_root_path, \"train\"),\n",
    "    clip_sampler=pytorchvideo.data.make_clip_sampler(\"random\", clip_duration),\n",
    "    decode_audio=False,\n",
    "    transform=train_transform,\n",
    ")\n",
    "\n",
    "val_transform = Compose(\n",
    "    [\n",
    "        ApplyTransformToKey(\n",
    "            key=\"video\",\n",
    "            transform=Compose(\n",
    "                [\n",
    "                    UniformTemporalSubsample(8),\n",
    "                    Lambda(lambda x: x / 255.0),\n",
    "                    Normalize(mean, std),\n",
    "                    Resize((resize_to, resize_to)),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "val_dataset = pytorchvideo.data.Ucf101(\n",
    "    data_path=os.path.join(dataset_root_path, \"val\"),\n",
    "    clip_sampler=pytorchvideo.data.make_clip_sampler(\"uniform\", clip_duration),\n",
    "    decode_audio=False,\n",
    "    transform=val_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6e61805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['video', 'video_name', 'video_index', 'clip_index', 'aug_index', 'label'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_video = next(iter(train_dataset))\n",
    "sample_video.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cb77348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video torch.Size([3, 8, 224, 224])\n",
      "video_name v_Basketball_g01_c01.avi\n",
      "video_index 210\n",
      "clip_index 0\n",
      "aug_index 0\n",
      "label 7\n"
     ]
    }
   ],
   "source": [
    "for k in sample_video:\n",
    "    if k == \"video\":\n",
    "        print(k, sample_video[\"video\"].shape)\n",
    "    else:\n",
    "        print(k, sample_video[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b421ff9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Basketball'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label[sample_video[k]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3995733d",
   "metadata": {},
   "source": [
    "Code related to data preparation utlities have been borrowed and repurposed from the following two articles:\n",
    "\n",
    "* https://www.tensorflow.org/tutorials/load_data/video\n",
    "* https://pytorchvideo.org/docs/tutorial_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d9490e",
   "metadata": {},
   "source": [
    "## TODOs\n",
    "\n",
    "- [ ] Provide appropriate credits\n",
    "- [ ] Add plenty of comments\n",
    "- [ ] Training and inference\n",
    "- [ ] Commentary\n",
    "- [ ] Code formatting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
