{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "single-arnold",
   "metadata": {},
   "source": [
    "# Huggingface Sagemaker-sdk - Run a batch transform inference job with ðŸ¤— Transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-politics",
   "metadata": {},
   "source": [
    "1. [Introduction](#Introduction)  \n",
    "2. [Run Batch Transform after training a model](#Run-Batch-Transform-after-training-a-model)  \n",
    "3. [Run Batch Transform Inference Job with a fine-tuned model using `jsonl`](#Run-Batch-Transform-Inference-Job-with-a-fine-tuned-model-using-jsonl)   \n",
    "4. [Run Batch Transform Inference Job with a fine-tuned model using `csv`](#Run-Batch-Transform-Inference-Job-with-a-fine-tuned-model-using-csv)  \n",
    "\n",
    "Welcome to this getting started guide, we will use the new Hugging Face Inference DLCs and Amazon SageMaker Python SDK to deploy two transformer model for inference. \n",
    "In the first example we deploy a trained Hugging Face Transformer model on to SageMaker for inference.\n",
    "In the second example we directly deploy one of the 10 000+ Hugging Face Transformers from the [Hub](https://huggingface.co/models) to Amazon SageMaker for Inference.<"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-visiting",
   "metadata": {},
   "source": [
    "## Run Batch Transform after training a model \n",
    "_not included in the notebook_\n",
    "\n",
    "After you train a model, you can use [Amazon SageMaker Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html) to perform inferences with the model. In Batch Transform you provide your inference data as a S3 uri and SageMaker will care of downloading it, running the prediction and uploading the results afterwards to S3 again. You can find more documentation for Batch Transform [here](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html)\n",
    "\n",
    "If you trained the model using the **HuggingFace estimator**, you can invoke `transformer()` method to create a transform job for a model based on the training job.\n",
    "\n",
    "```python\n",
    "batch_job = huggingface_estimator.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c5.2xlarge',\n",
    "    strategy='SingleRecord')\n",
    "\n",
    "\n",
    "batch_job.transform(\n",
    "    data='s3://s3-uri-to-batch-data',\n",
    "    content_type='application/json',    \n",
    "    split_type='Line')\n",
    "```\n",
    "For more details about what can be specified here, see [API docs](https://sagemaker.readthedocs.io/en/stable/overview.html#sagemaker-batch-transform).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-dover",
   "metadata": {},
   "source": [
    "# Run Batch Transform Inference Job with a fine-tuned model using `jsonl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "working-henry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting sagemaker>=2.48.0\n",
      "  Downloading sagemaker-2.52.2.tar.gz (436 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 436 kB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: datasets in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (1.6.2)\n",
      "Collecting datasets\n",
      "  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 264 kB 11.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from sagemaker>=2.48.0) (20.3.0)\n",
      "Requirement already satisfied: boto3>=1.16.32 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from sagemaker>=2.48.0) (1.16.43)\n",
      "Requirement already satisfied: google-pasta in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from sagemaker>=2.48.0) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from sagemaker>=2.48.0) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.1 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from sagemaker>=2.48.0) (3.15.5)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from sagemaker>=2.48.0) (0.1.5)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from sagemaker>=2.48.0) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from sagemaker>=2.48.0) (3.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from sagemaker>=2.48.0) (20.9)\n",
      "Requirement already satisfied: pandas in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from sagemaker>=2.48.0) (1.2.3)\n",
      "Requirement already satisfied: pathos in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from sagemaker>=2.48.0) (0.2.7)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from boto3>=1.16.32->sagemaker>=2.48.0) (0.3.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from boto3>=1.16.32->sagemaker>=2.48.0) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.43 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from boto3>=1.16.32->sagemaker>=2.48.0) (1.19.52)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from botocore<1.20.0,>=1.19.43->boto3>=1.16.32->sagemaker>=2.48.0) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from botocore<1.20.0,>=1.19.43->boto3>=1.16.32->sagemaker>=2.48.0) (1.26.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from importlib-metadata>=1.4.0->sagemaker>=2.48.0) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from packaging>=20.0->sagemaker>=2.48.0) (2.4.7)\n",
      "Requirement already satisfied: six>=1.9 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from protobuf>=3.1->sagemaker>=2.48.0) (1.15.0)\n",
      "Requirement already satisfied: xxhash in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (2.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: dill in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (0.3.3)\n",
      "Collecting fsspec>=2021.05.0\n",
      "  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 118 kB 7.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub<0.1.0 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (0.0.12)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: tqdm>=4.42 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (4.49.0)\n",
      "Requirement already satisfied: multiprocess in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (0.70.11.1)\n",
      "Requirement already satisfied: filelock in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from pandas->sagemaker>=2.48.0) (2021.1)\n",
      "Requirement already satisfied: pox>=0.2.9 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from pathos->sagemaker>=2.48.0) (0.2.9)\n",
      "Requirement already satisfied: ppft>=1.6.6.3 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from pathos->sagemaker>=2.48.0) (1.6.6.3)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.52.2-py2.py3-none-any.whl size=613974 sha256=00faee031381f800570e1ceb353ce0a920264e22275f37ce4e96b57b13a44140\n",
      "  Stored in directory: /private/var/folders/v2/jqc0m2dd6gs20k4c_rjmd66m0000gn/T/pip-ephem-wheel-cache-kbcbym4x/wheels/f9/58/05/17415b8d285b9d15a7dd2d717e0f5143669d5280174ef6ae33\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: fsspec, sagemaker, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 0.8.7\n",
      "    Uninstalling fsspec-0.8.7:\n",
      "      Successfully uninstalled fsspec-0.8.7\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.47.3.dev0\n",
      "    Uninstalling sagemaker-2.47.3.dev0:\n",
      "      Successfully uninstalled sagemaker-2.47.3.dev0\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 1.6.2\n",
      "    Uninstalling datasets-1.6.2:\n",
      "      Successfully uninstalled datasets-1.6.2\n",
      "Successfully installed datasets-1.11.0 fsspec-2021.7.0 sagemaker-2.52.2\n"
     ]
    }
   ],
   "source": [
    "!pip install \"sagemaker>=2.48.0\" \"datasets==1.11\" --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-march",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "\n",
    "In this example we are using the `datasets` library to load a dataset and pre-process it into a `.jsonl` format to make it compatible for batch transform. You could also provide a `.csv` instead of a `.jsonl` file. But the tasks `\"zero-shot-classification\"` and `\"table-question-answering\"` are currently nto supported with `csv` due to their nested input structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "north-roller",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/Users/philipp/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must setup local AWS configuration with a region supported by SageMaker.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-54819983d6e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# uploads a given file to S3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0ms3_file_uri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mS3Uploader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"batch_transform/{local_file}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/hf/lib/python3.8/site-packages/sagemaker/s3.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(local_path, desired_s3_uri, kms_key, sagemaker_session)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \"\"\"\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0msagemaker_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msagemaker_session\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_s3_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesired_s3_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkms_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hf/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, boto_session, sagemaker_client, sagemaker_runtime_client, sagemaker_featurestore_runtime_client, default_bucket)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         self._initialize(\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mboto_session\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboto_session\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0msagemaker_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hf/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, boto_session, sagemaker_client, sagemaker_runtime_client, sagemaker_featurestore_runtime_client)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_region_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboto_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregion_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_region_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    145\u001b[0m                 \u001b[0;34m\"Must setup local AWS configuration with a region supported by SageMaker.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Must setup local AWS configuration with a region supported by SageMaker."
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "local_file = \"imbd_input.jsonl\"\n",
    "\n",
    "# load dataset imdb dataset from `datasets``\n",
    "dataset = load_dataset(\"imdb\",split=[\"test\"])[0]\n",
    "\n",
    "# map_to_jsonl\n",
    "with open(local_file, \"w\") as jsonl_file:\n",
    "    for sample in dataset:\n",
    "        json.dump({\"inputs\":sample[\"text\"]},jsonl_file)\n",
    "        jsonl_file.write(\"\\n\")\n",
    "        \n",
    "# uploads a given file to S3.\n",
    "s3_file_uri = S3Uploader.upload(local_file,f\"batch_transform/{local_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-complex",
   "metadata": {},
   "source": [
    "## Create Inference Transformer to run the batch job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "# Hub Model configuration. <https://huggingface.co/models>\n",
    "hub = {\n",
    "    'HF_MODEL_ID':'distilbert-base-uncased-finetuned-sst-2-english',\n",
    "    'HF_TASK':'text-classification'\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   env=hub, # configuration for loading model from Hub\n",
    "   role=role, # iam role with permissions to create an Endpoint\n",
    "   transformers_version=\"4.6\", # transformers version used\n",
    "   pytorch_version=\"1.7\", # pytorch version used\n",
    "   py_version='py36', # python version used\n",
    ")\n",
    "\n",
    "# create Transformer to run our batch job\n",
    "batch_job = huggingface_model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c5.2xlarge',\n",
    "    strategy='SingleRecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starts batch transform job and uses s3 data as input\n",
    "batch_job.transform(\n",
    "    data=s3_file_uri,\n",
    "    content_type='application/json',    \n",
    "    split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-leave",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get results \n",
    "batch_job.output_path"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c281c456f1b8161c8906f4af2c08ed2c40c50136979eaae69688b01f70e9f4a9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
