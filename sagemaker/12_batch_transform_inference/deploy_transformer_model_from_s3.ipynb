{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Huggingface Sagemaker-sdk - Run a batch transform inference job with ðŸ¤— Transformers\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. [Introduction](#Introduction)  \n",
    "2. [Run Batch Transform after training a model](#Run-Batch-Transform-after-training-a-model)  \n",
    "3. [Run Batch Transform Inference Job with a fine-tuned model using `jsonl`](#Run-Batch-Transform-Inference-Job-with-a-fine-tuned-model-using-jsonl)   \n",
    "4. [Run Batch Transform Inference Job with a fine-tuned model using `csv`](#Run-Batch-Transform-Inference-Job-with-a-fine-tuned-model-using-csv)  \n",
    "\n",
    "Welcome to this getting started guide, we will use the new Hugging Face Inference DLCs and Amazon SageMaker Python SDK to deploy two transformer model for inference. \n",
    "In the first example we deploy a trained Hugging Face Transformer model on to SageMaker for inference.\n",
    "In the second example we directly deploy one of the 10 000+ Hugging Face Transformers from the [Hub](https://huggingface.co/models) to Amazon SageMaker for Inference.<"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run Batch Transform after training a model \n",
    "_not included in the notebook_\n",
    "\n",
    "After you train a model, you can use [Amazon SageMaker Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html) to perform inferences with the model. In Batch Transform you provide your inference data as a S3 uri and SageMaker will care of downloading it, running the prediction and uploading the results afterwards to S3 again. You can find more documentation for Batch Transform [here](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html)\n",
    "\n",
    "If you trained the model using the **HuggingFace estimator**, you can invoke `transformer()` method to create a transform job for a model based on the training job.\n",
    "\n",
    "```python\n",
    "batch_job = huggingface_estimator.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c5.2xlarge',\n",
    "    strategy='SingleRecord')\n",
    "\n",
    "\n",
    "batch_job.transform(\n",
    "    data='s3://s3-uri-to-batch-data',\n",
    "    content_type='application/json',    \n",
    "    split_type='Line')\n",
    "```\n",
    "For more details about what can be specified here, see [API docs](https://sagemaker.readthedocs.io/en/stable/overview.html#sagemaker-batch-transform).\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run Batch Transform Inference Job with a fine-tuned model using `jsonl`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!pip install \"sagemaker>=2.48.0\" \"datasets==1.11\" --upgrade"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting sagemaker>=2.48.0\n",
      "  Downloading sagemaker-2.52.2.tar.gz (436 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 436 kB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: datasets in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (1.6.2)\n",
      "Collecting datasets\n",
      "  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 264 kB 11.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from sagemaker>=2.48.0) (20.3.0)\n",
      "Requirement already satisfied: boto3>=1.16.32 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from sagemaker>=2.48.0) (1.16.43)\n",
      "Requirement already satisfied: google-pasta in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from sagemaker>=2.48.0) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from sagemaker>=2.48.0) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.1 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from sagemaker>=2.48.0) (3.15.5)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from sagemaker>=2.48.0) (0.1.5)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from sagemaker>=2.48.0) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from sagemaker>=2.48.0) (3.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from sagemaker>=2.48.0) (20.9)\n",
      "Requirement already satisfied: pandas in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from sagemaker>=2.48.0) (1.2.3)\n",
      "Requirement already satisfied: pathos in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from sagemaker>=2.48.0) (0.2.7)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from boto3>=1.16.32->sagemaker>=2.48.0) (0.3.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from boto3>=1.16.32->sagemaker>=2.48.0) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.43 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from boto3>=1.16.32->sagemaker>=2.48.0) (1.19.52)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from botocore<1.20.0,>=1.19.43->boto3>=1.16.32->sagemaker>=2.48.0) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from botocore<1.20.0,>=1.19.43->boto3>=1.16.32->sagemaker>=2.48.0) (1.26.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from importlib-metadata>=1.4.0->sagemaker>=2.48.0) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from packaging>=20.0->sagemaker>=2.48.0) (2.4.7)\n",
      "Requirement already satisfied: six>=1.9 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from protobuf>=3.1->sagemaker>=2.48.0) (1.15.0)\n",
      "Requirement already satisfied: xxhash in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (2.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: dill in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (0.3.3)\n",
      "Collecting fsspec>=2021.05.0\n",
      "  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 118 kB 7.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub<0.1.0 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (0.0.12)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: tqdm>=4.42 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (4.49.0)\n",
      "Requirement already satisfied: multiprocess in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from datasets) (0.70.11.1)\n",
      "Requirement already satisfied: filelock in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from pandas->sagemaker>=2.48.0) (2021.1)\n",
      "Requirement already satisfied: pox>=0.2.9 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from pathos->sagemaker>=2.48.0) (0.2.9)\n",
      "Requirement already satisfied: ppft>=1.6.6.3 in /Users/philipp/anaconda3/envs/hf/lib/python3.8/site-packages (from pathos->sagemaker>=2.48.0) (1.6.6.3)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.52.2-py2.py3-none-any.whl size=613974 sha256=00faee031381f800570e1ceb353ce0a920264e22275f37ce4e96b57b13a44140\n",
      "  Stored in directory: /private/var/folders/v2/jqc0m2dd6gs20k4c_rjmd66m0000gn/T/pip-ephem-wheel-cache-kbcbym4x/wheels/f9/58/05/17415b8d285b9d15a7dd2d717e0f5143669d5280174ef6ae33\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: fsspec, sagemaker, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 0.8.7\n",
      "    Uninstalling fsspec-0.8.7:\n",
      "      Successfully uninstalled fsspec-0.8.7\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.47.3.dev0\n",
      "    Uninstalling sagemaker-2.47.3.dev0:\n",
      "      Successfully uninstalled sagemaker-2.47.3.dev0\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 1.6.2\n",
      "    Uninstalling datasets-1.6.2:\n",
      "      Successfully uninstalled datasets-1.6.2\n",
      "Successfully installed datasets-1.11.0 fsspec-2021.7.0 sagemaker-2.52.2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Pre-Processing\n",
    "\n",
    "In this example we are using the `datasets` library to load a dataset and pre-process it into a `.jsonl` format to make it compatible for batch transform. You could also provide a `.csv` instead of a `.jsonl` file. But the tasks `\"zero-shot-classification\"` and `\"table-question-answering\"` are currently nto supported with `csv` due to their nested input structure."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "import sagemaker\n",
    "from sagemaker.s3 import S3Uploader,s3_path_join\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "local_file = \"sst_input.jsonl\"\n",
    "dataset_name = \"sst\"\n",
    "\n",
    "# load dataset imdb dataset from `datasets``\n",
    "dataset = load_dataset(dataset_name,split=[\"test\"])[0]\n",
    "print(f\"The {dataset_name} dataset used consist of {len(dataset)} datapoints\")\n",
    "\n",
    "# map_to_jsonl\n",
    "with open(local_file, \"w\") as jsonl_file:\n",
    "    for sample in dataset:\n",
    "        json.dump({\"inputs\":sample[\"sentence\"]},jsonl_file)\n",
    "        jsonl_file.write(\"\\n\")\n",
    "        \n",
    "# uploads a given file to S3.\n",
    "upload_path = s3_path_join(\"s3://\",sagemaker_session_bucket,\"batch_transform\")\n",
    "s3_file_uri = S3Uploader.upload(local_file,upload_path)\n",
    "\n",
    "print(f\"{local_file} uploaded to {s3_file_uri}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The created file looks like this\n",
    "\n",
    "```json\n",
    "{\"inputs\": \"I went and saw this movie last night after being ...\"}\n",
    "{\"inputs\": \"Actor turned director Bill Paxton follows up his promising debut ...\"}\n",
    "{\"inputs\": \"As a recreational golfer with some knowledge of the sport's history ...\"}\n",
    "{\"inputs\": \"Maybe I'm reading into this too much, but I wonder how much of a hand Hongsheng had ...\"}\n",
    "{\"inputs\": \"I loved this movie from beginning to end.I am a musician and i let drugs get in the way of my some of the things i used to love(skateboarding,drawing) ...\"}\n",
    "....\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Inference Transformer to run the batch job"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "# Hub Model configuration. <https://huggingface.co/models>\n",
    "hub = {\n",
    "    'HF_MODEL_ID':'distilbert-base-uncased-finetuned-sst-2-english',\n",
    "    'HF_TASK':'text-classification'\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   env=hub, # configuration for loading model from Hub\n",
    "   role=role, # iam role with permissions to create an Endpoint\n",
    "   transformers_version=\"4.6\", # transformers version used\n",
    "   pytorch_version=\"1.7\", # pytorch version used\n",
    "   py_version='py36', # python version used\n",
    ")\n",
    "\n",
    "# create Transformer to run our batch job\n",
    "batch_job = huggingface_model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    output_path=upload_path, # we are using the same s3 path to save the output with the input\n",
    "    strategy='SingleRecord')\n",
    "\n",
    "# starts batch transform job and uses s3 data as input\n",
    "batch_job.transform(\n",
    "    data=s3_file_uri,\n",
    "    content_type='application/json',    \n",
    "    split_type='Line')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "# creating s3 uri for result file -> input file + .out\n",
    "output_file = f\"{local_file}.out\"\n",
    "output_path = s3_path_join(upload_path,output_file)\n",
    "\n",
    "# download file\n",
    "S3Downloader.download(output_path,'.')\n",
    "\n",
    "with open(output_file) as output_file:\n",
    "    print(output_file.readline()[:250])"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c281c456f1b8161c8906f4af2c08ed2c40c50136979eaae69688b01f70e9f4a9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}