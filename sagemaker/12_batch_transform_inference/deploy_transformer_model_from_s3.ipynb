{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "recognized-lottery",
   "metadata": {},
   "source": [
    "# Huggingface Sagemaker-sdk - Run a batch transform inference job with ðŸ¤— Transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-video",
   "metadata": {},
   "source": [
    "1. [Introduction](#Introduction)  \n",
    "2. [Run Batch Transform after training a model](#Run-Batch-Transform-after-training-a-model)  \n",
    "3. [Run Batch Transform Inference Job with a fine-tuned model using `jsonl`](#Run-Batch-Transform-Inference-Job-with-a-fine-tuned-model-using-jsonl)   \n",
    "4. [Run Batch Transform Inference Job with a fine-tuned model using `csv`](#Run-Batch-Transform-Inference-Job-with-a-fine-tuned-model-using-csv)  \n",
    "\n",
    "Welcome to this getting started guide, we will use the new Hugging Face Inference DLCs and Amazon SageMaker Python SDK to deploy two transformer model for inference. \n",
    "In the first example we deploy a trained Hugging Face Transformer model on to SageMaker for inference.\n",
    "In the second example we directly deploy one of the 10 000+ Hugging Face Transformers from the [Hub](https://huggingface.co/models) to Amazon SageMaker for Inference.<"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-excuse",
   "metadata": {},
   "source": [
    "## Run Batch Transform after training a model \n",
    "_not included in the notebook_\n",
    "\n",
    "After you train a model, you can use [Amazon SageMaker Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html) to perform inferences with the model. In Batch Transform you provide your inference data as a S3 uri and SageMaker will care of downloading it, running the prediction and uploading the results afterwards to S3 again. You can find more documentation for Batch Transform [here](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html)\n",
    "\n",
    "If you trained the model using the **HuggingFace estimator**, you can invoke `transformer()` method to create a transform job for a model based on the training job.\n",
    "\n",
    "```python\n",
    "batch_job = huggingface_estimator.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c5.2xlarge',\n",
    "    strategy='SingleRecord')\n",
    "\n",
    "\n",
    "batch_job.transform(\n",
    "    data='s3://s3-uri-to-batch-data',\n",
    "    content_type='application/json',    \n",
    "    split_type='Line')\n",
    "```\n",
    "For more details about what can be specified here, see [API docs](https://sagemaker.readthedocs.io/en/stable/overview.html#sagemaker-batch-transform).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-marshall",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"sagemaker>=2.48.0\" \"datasets==1.11\" --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-tanzania",
   "metadata": {},
   "source": [
    "# Run Batch Transform Inference Job with a fine-tuned model using `jsonl`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-bleeding",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "\n",
    "In this example we are using the provided `tweet_data.csv` as dataset. The `csv` contains ~1800 tweets about different airlines. The `csv` contains 1 column `\"inputs\"` with the tweets. To use this `csv` we need to convert it into a `jsonl` file and upload it to s3. Due to the complex structure of text are only `jsonl` file supported for batch transform. \n",
    "\n",
    "_**NOTE**: While preprocessing you need to make sure that your `inputs` fit the `max_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import sagemaker\n",
    "from sagemaker.s3 import S3Uploader,s3_path_join\n",
    "\n",
    "# get the s3 bucket\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "# datset files\n",
    "dataset_csv_file=\"tweet_data.csv\"\n",
    "dataset_jsonl_file=\"tweet_data.jsonl\"\n",
    "\n",
    "with open(dataset_csv_file, \"r+\") as infile, open(dataset_jsonl_file, \"w+\") as outfile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    for row in reader:\n",
    "        json.dump(row, outfile)\n",
    "        outfile.write('\\n')\n",
    "        \n",
    "# uploads a given file to S3.\n",
    "upload_path = s3_path_join(\"s3://\",sagemaker_session_bucket,\"batch_transform\")\n",
    "s3_file_uri = S3Uploader.upload(dataset_jsonl_file,upload_path)\n",
    "\n",
    "print(f\"{local_file_processed} uploaded to {s3_file_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-grant",
   "metadata": {},
   "source": [
    "The created file looks like this\n",
    "\n",
    "```json\n",
    "{\"inputs\": \"I went and saw this movie last night after being ...\"}\n",
    "{\"inputs\": \"Actor turned director Bill Paxton follows up his promising debut ...\"}\n",
    "{\"inputs\": \"As a recreational golfer with some knowledge of the sport's history ...\"}\n",
    "{\"inputs\": \"Maybe I'm reading into this too much, but I wonder how much of a hand Hongsheng had ...\"}\n",
    "{\"inputs\": \"I loved this movie from beginning to end.I am a musician and i let drugs get in the way of my some of the things i used to love(skateboarding,drawing) ...\"}\n",
    "....\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-policy",
   "metadata": {},
   "source": [
    "## Create Inference Transformer to run the batch job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "# Hub Model configuration. <https://huggingface.co/models>\n",
    "hub = {\n",
    "    'HF_MODEL_ID':'distilbert-base-uncased-finetuned-sst-2-english',\n",
    "    'HF_TASK':'text-classification'\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   env=hub, # configuration for loading model from Hub\n",
    "   role=role, # iam role with permissions to create an Endpoint\n",
    "   transformers_version=\"4.6\", # transformers version used\n",
    "   pytorch_version=\"1.7\", # pytorch version used\n",
    "   py_version='py36', # python version used\n",
    ")\n",
    "\n",
    "# create Transformer to run our batch job\n",
    "batch_job = huggingface_model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    output_path=upload_path, # we are using the same s3 path to save the output with the input\n",
    "    strategy='SingleRecord')\n",
    "\n",
    "# starts batch transform job and uses s3 data as input\n",
    "batch_job.transform(\n",
    "    data=s3_file_uri,\n",
    "    content_type='application/json',    \n",
    "    split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "# creating s3 uri for result file -> input file + .out\n",
    "output_file = f\"{local_file}.out\"\n",
    "output_path = s3_path_join(upload_path,output_file)\n",
    "\n",
    "# download file\n",
    "S3Downloader.download(output_path,'.')\n",
    "\n",
    "batch_transform_result = []\n",
    "with open(output_file) as f:\n",
    "    for line in f:\n",
    "        batch_transform_result.append(json.loads(line))\n",
    "\n",
    "# print results \n",
    "print(batch_transform_result[:3])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c281c456f1b8161c8906f4af2c08ed2c40c50136979eaae69688b01f70e9f4a9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
